{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Learning of Geometry and Context for Deep Stereo Regression\n",
    "\n",
    "[arXiv](https://arxiv.org/abs/1703.04309) | [TensorFlow 1](https://github.com/Jiankai-Sun/GC-Net) | [TensorFlow 2](https://github.com/MaidouPP/gc_net_stereo) | [Keras](https://github.com/LinHungShi/GCNetwork)\n",
    "\n",
    "* siamese residual FCN提特征 + 构建cost volume + **3D CNN学习正则化 + soft argmin**\n",
    "* 提出soft argmin, 解决了普通argmin的两个问题: **离散**(我们期望能估计subpixel)和**不可微**(loss无法反传). 从而能直接从cost volume得到disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/parameters.png)\n",
    "\n",
    "![](imgs/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unary Features\n",
    "不用raw pixels而用feature representation, 从而对photometric appearance更robust的matching.\n",
    "\n",
    "只是一个简单的residual FCN, 这里讨论一下网络深度与参数量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN to learn regularization\n",
    "\n",
    "用soft argmin从cost volume直接出regression结果是很好的想法, 模型有望做的非常compact, 然而从论文来看. 学习regularization的3D CNN部分不得不做的很臃肿, 最终导致了非常大的显存占用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft ArgMin\n",
    "\n",
    "***\n",
    "\n",
    "![](imgs/differentiable_argmin.png)\n",
    "\n",
    "\n",
    "提出Soft Argmin\n",
    "$$soft \\space argmin := \\Sigma^{D_{max}}_{d=0}{d \\times \\sigma(-c_d)}$$\n",
    "\n",
    "其中, $\\sigma(\\cdot)$为softmax\n",
    "\n",
    "解决了普通argmin的两个问题:\n",
    "* 只能得到整数解, 而我们希望能得到subpixel的disparity\n",
    "* 不可微, 加到loss function里是不能BP的\n",
    "\n",
    "\n",
    "同时, 如图所示, 在面临multi-modal的输入时, 有可能出现偏移, 只能寄希望于前面的网络可以学会一个uni-modal的分布\n",
    "\n",
    "\n",
    "> However, compared to the argmin operation, its output is influenced by all values. This leaves it susceptible to multi-modal distributions, as the output will not take the most likely. Rather, it will estimate a weighted average of all modes. To overcome this limitation, we rely on the network’s regularization to produce a disparity probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多峰问题测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_indices(cv, S):\n",
    "    \"\"\"\n",
    "    build indices from a cost volume\n",
    "    \n",
    "    cv: (B, C, H, W)\n",
    "    indices: (B, C_h, C_w, H, W)\n",
    "    \"\"\"\n",
    "    C_h, C_w = cv.size()\n",
    "    indices = torch.zeros((2*S+1, 2*S+1, 2))\n",
    "    indices[..., 0] = torch.linspace(-S, S, 2*S+1)[:, None]\n",
    "    indices[..., 1] = torch.linspace(-S, S, 2*S+1)\n",
    "    # indices = indices.view(1, 2*S+1, 2*S+1, 2, 1, 1).expand(B, C_h, C_w, 2, H, W)\n",
    "    # print(indices[..., 0, 0,0])\n",
    "    # quit()\n",
    "\n",
    "\n",
    "    indices_y = torch.linspace(-S, S, 2*S+1).view(2*S+1, 1).expand(2*S+1, 2*S+1)\n",
    "    indices_x = torch.linspace(-S, S, 2*S+1).view(1, 2*S+1).expand(2*S+1, 2*S+1)\n",
    "\n",
    "    return indices_y, indices_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_flow_soft(corr):\n",
    "    C_h, C_w = corr.size()\n",
    "    softmax = F.softmax(corr.view(C_h*C_w), dim = 0).view(C_h, C_w)\n",
    "    indices_y, indices_x = get_indices(corr, C_h // 2)\n",
    "    soft_argmax_y = (softmax * indices_y).sum()\n",
    "    soft_argmax_x = (softmax * indices_x).sum()\n",
    "    print(torch.cat([indices_y, indices_x], dim = 1))\n",
    "    return torch.stack([soft_argmax_x, soft_argmax_y], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_flow_hard(corr):\n",
    "    max, _ = corr.max(1)\n",
    "    _, flow_y = max.max(0)\n",
    "\n",
    "    max, _ = corr.max(0)\n",
    "    _, flow_x = max.max(0)\n",
    "    flow_hard = torch.stack([flow_x, flow_y], dim = 0).float() - (corr.size(0) // 2)\n",
    "    return flow_hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单峰, OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_uni_modal = torch.Tensor(\n",
    "    [\n",
    "        [1  ,   2,    3],\n",
    "        [0  ,   1,    0],\n",
    "        [0  , 100,    0],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1., -1.,  0.,  1.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  1.],\n",
      "        [ 1.,  1.,  1., -1.,  0.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6.4600e-43,  1.0000e+00])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_flow_soft(corr_uni_modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_flow_hard(corr_uni_modal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多峰, 出现偏移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_multi_modal = torch.Tensor(\n",
    "    [\n",
    "        [100  ,   100,    3],\n",
    "        [0  ,   1,    0],\n",
    "        [0  ,  4.5,    101],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1., -1.,  0.,  1.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  1.],\n",
      "        [ 1.,  1.,  1., -1.,  0.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3642,  0.1522])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_flow_soft(corr_multi_modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_flow_hard(corr_multi_modal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
