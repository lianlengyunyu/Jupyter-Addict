{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperPoint: Self-Supervised Interest Point Detection and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interest Point即VO中的features, 离散点的预测在其他领域有很成熟的有监督学习方案, 如人体关键点检测, 然而对于本任务, Interest Point是ill-defined, 这就导致了不可能有大量的Interest Point标注来供模型训练, 所以无监督学习或本文的自监督学习成为了关键.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过图形学的方式生成数据来训练**MagicPoint**, 发现与传统的检测器相比丢失了许多潜在的Interest Points, 所有又提出了**Homographic Adaptation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "利用图形学的方法, 根据给定的Interest Points渲染出图像(基础立体图形), 然后做同形的augmentation, 作为MagicPoint的dataset. 尽管只用了基础图形, 但能很好地泛化到现实数据上\n",
    "\n",
    "论文评测了多种方法在他们数据集上的效果, 发现自己的MagicPoint很厉害(这不是废话么……)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture\n",
    "\n",
    "用VGG作提取特征的backbone(总stride为8), 然后连接着**Interest Point Decoder**和**Discriptor Decoder**两个Task-specific network\n",
    "\n",
    "- **Interest Point Decoder**没有用FCN Encoder-Decoder中常用的Transposed Conv, 而是用了Depth to wise的方法\n",
    "\n",
    "- **Discriptor Decoder**没有还原大小, 而是先输出再用bicubic interpolation来放大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
